---
title: Tidy DataFrames but not Tibbles
author: Jonathan Carroll
date: '2024-08-11'
categories:
  - bioconductor
  - rstats
tags:
  - bioconductor
  - rstats
slug: tidy-dataframes-but-not-tibbles
editor_options:
  chunk_output_type: console
---

```{r, setup, include = FALSE}
knitr::opts_chunk$set(
  class.output  = "bg-success",
  class.message = "bg-info text-info",
  class.warning = "bg-warning text-warning",
  class.error   = "bg-danger text-danger"
)
```

A while ago (2019 seems so long ago now) I started working on something I
thought was interesting but which never really got any traction. It has
potential once more, so it's about time I wrote up what it does and why I think
it's a useful idea. I'm going to talk about using the {dplyr} package on some
data with rows and columns, but we're not talking about `data.frame`s or
`tibble`s...

<!--more-->

A while ago (2019 seems so long ago now) I started working on something I
thought was interesting but which never really got any traction. It has
potential once more, so it's about time I wrote up what it does and why I think
it's a useful idea. I'm going to talk about using the {dplyr} package on some
data with rows and columns, but we're not talking about `data.frame`s or
`tibble`s...

Okay, I probably do need to talk about them a little to start with. 

I'm also taking this opportunity to reinforce my own understanding of all 
these pieces - I find the best way to learn something is to teach it.

## `data.frame`

One of the basic building blocks of data in R is the `data.frame` - technically
a list of vectors (vectors must have the same 'type' but lists don't have this
restriction) where the vectors are all the same length. An example looks like
this

```{r}
d <- data.frame(x = 2:5, y = LETTERS[2:5], z = 4:7+2i)
d
```

If we unpack that a bit, it _is_ just a list of vectors

```{r}
unclass(d)
```

and there we see one more feature; they have an attribute `row.names`. By default 
these are just numbers (encoded as strings) which we can get to with the `rownames()` 
function

```{r}
rownames(d)
```

If you've read any guides to using R you will likely have seen the `mtcars` dataset 
which features these row names prominently - here's the first 4 rows and columns

```{r}
mtcars[1:4, 1:4]
```

We can extract those row names 

```{r}
rownames(mtcars[1:4, 1:4])
```

This "row name" data sort of sits off to the side of the data object, but yes, 
they _could_ live "in" the data just fine as their own vector. That's the approach 
that the tidyverse takes with `tibble`s. There's one other benefit to these that 
is often overlooked, though.

In the above examples I've extracted some rows of the `mtcars` `data.frame` with 
indices, but the `[` method works just as well with row identifiers (strings)...

```{r}
mercs <- grep("Merc", rownames(mtcars), value = TRUE)
mercs
mtcars[mercs, 1:4]
```

You're probably more familiar with this when subsetting columns, in which case 
you're using the column names in exactly the same way

```{r}
metrics <- c("mpg", "hp", "drat")
mtcars[mercs, metrics]
```

As we'll see, this becomes very convenient when we have meaningful identifiers 
in both dimensions.

## {tibble}

A `tibble` is almost exactly like a `data.frame` except that the print method shows
it a bit differently

```{r}
tbl <- tibble::as_tibble(mtcars[1:4, 1:4])
tbl
```

and the row names are gone. That's by design, and enforced quite strongly - if I 
tried to add them back, {tibble} complains, and refuses

```{r}
rownames(tbl) <- rownames(mtcars)[1:4]
tbl
```

The world moves on, though.

If you _have_ row names that you really want to keep, {tibble} has a way to get them 
into their own column so that they'll be preserved in a `tibble`

```{r}
tbl_rows <- mtcars[6:10, 1:5] |> 
  tibble::rownames_to_column() |> 
  tibble::as_tibble()
tbl_rows
```

To get the named subsetting behaviour described earlier, we have to specify the
`"rowname"` column in the output and do some filtering on it to get the rows we
want

```{r}
tbl_rows[tbl_rows$rowname %in% mercs, c("rowname", metrics)]
```

Of course, there's a better way to subset a `tibble`...

## {dplyr}

In terms of interacting with these objects, {dplyr} is great - it's reminiscent
of SQL syntax (`SELECT`, `GROUP BY`, ... look, it's not 1:1, but it's somewhat
familiar) and makes for a really clean pipeline of data processing - it got in
early supporting the {magrittr} pipe and encouraging a 'data as the first
argument' construction that meant piping from one function to another went
smoothly.

There's not much in {dplyr} that you couldn't do with a bunch of base functions 
if you were so inclined - and some people have gone as far as proving that with 
non-dplyr packages with matching functions but base internals, forgoing {dplyr}'s
ability to connect to a database with the exact same code you would use on a 
local `tibble` ({dbplyr} translates the R calls into native SQL syntax behind the 
scenes) for some more debuggable code, e.g. [{poorman}](https://nathaneastwood.github.io/poorman/).

{dplyr} functions mostly return the same class as the input; if you `mutate` a
`data.frame` you'll get back a `data.frame` (which wasn't always the case, but
is less surprising now)

```{r}
mtcars[1:5, 1:6] |> 
  dplyr::mutate(pwr = hp / wt)
```

One feature that `tibble` adds on top of `data.frame` is the concept of "groups". 
For this reason, if you perform a grouping on a `data.frame` you'll get a `tibble` 
because that's the only supported option

```{r}
# slice(1) on a data.frame returns 1 row of a data.frame
mtcars |> 
  dplyr::slice(1)

# slice(1) on a grouped tibble returns 1 row _per group_ 
mtcars |> 
  dplyr::group_by(gear, am) |> 
  dplyr::slice(1)
```

{tibble} stores this information in a special `"groups"` attribute, and ensures 
that {dplyr} functions are aware of it. It also prints this information above 
the object (plus the number of resulting 'groups').

Is there anything it can't do?

## A Whole New World

That ended up being a lot of background, glad to see you're still with me. That's 
{dplyr} which can take either a `data.frame` or a `tibble` to do lots of useful 
operations on data. If, like me prior to joining the world of computational 
biology, you thought that was all there was to it, the next part comes as a bit of 
an eye opener. 

Just like in a video game where all of a sudden the map is revealed to be twice as 
large as you knew it, there's an entire world of R packages beyond CRAN, mainly 
targeted at computational biology/bioinformatics, known as [Bioconductor](https://bioconductor.org/). 
This is well supported by the R project itself, but you could spend your life 
writing R analyses and never use it if you aren't working on bioinfo stuff.

I don't think I'd used anything from Bioconductor before I joined a large biotech - 
incidentally the one at which Robert Gentleman himself was a senior director in 
bioinformatics and computational biology until just a couple of years before I 
joined. Over the next few years, though, I'd become very familiar with the packages 
on offer in that space.

In the world of sequencing data, the humble `data.frame` just doesn't have the 
right amount of structure - rectangular data is great, but no matter which way 
you pivot (wide or long) you're going to have some trouble representing all the 
different qualities and quantities associated with a sample; for example representing 
the level of expression of some gene for some samples belonging to some subject, 
where both the subject and the sample have metadata, as does the experiment itself, 
as do the genes. Keeping in mind that this might involve a thousand samples and 
many tens of thousands of genes, a flat table just won't cut it.

A better option is to create a different structure, one which keeps the different 
components (sample metadata, gene metadata) aligned and together, but not in the 
same table. Several of these have evolved over time, but a current favourite of 
the field is the `SummarizedExperiment` structure. This organises the components 
in a way that they can be stored and interrogated without having to perform a 
dozen filters to get to the corner of data you're interested in.

If we think of this like a database, we have a table for the actual measurements, 
another for the sample metadata, and another for the metadata on the things being 
observed (e.g. genes). The problem is, we need to define keys that link the 
different tables together. If our measurements were a giant matrix of values, e.g.

```{r}
expression_data <- matrix(c(2, 3, 1, 0, 9, 5, 3, 4, 5), ncol = 3)
expression_data
```

how would we know that the second column is for sample_Y and the third row is 
for gene_DEF? The matrix itself is numeric, so we can't just add a new row/column 
to store the sample/gene information, which is character.

No points for guessing that the intro above was for a reason - those attributes 
are now really useful.

```{r}
library(charcuterie)
rownames(expression_data) <- paste0("gene_", c("ABC", "DEF", "GHI"))
colnames(expression_data) <- paste0("sample_", chars("XYZ"))
expression_data
```

Much clearer! Even better, now we have a way to link up the metadata in either 
dimension.

For the samples, we can create a `data.frame` with the relevant metadata for 
each sample, and label each sample row with the relevant ID

```{r}
sample_metadata <- data.frame(name = c("Jim", "Jack", "Joe"), age = c(51, 53, 52))
rownames(sample_metadata) <- paste0("sample_", chars("XYZ"))
sample_metadata
```

Now we can imagine taking this metadata and sort of turning it sideways so that 
the labels align like interlocking puzzle pieces. These run across the columns, 
so we can call them the "column data" of the final structure. Similarly, we can 
do the same for the genes, perhaps annotating the chromosome they're on, and 
other identifiers, and use these as the "row data".

This is the basic structure of the `SummarizedExperiment`, but all is not well.

Bioconductor leans heavily into the S4 object model, making use of multiple 
dispatch as well as object validation. For example, if I wanted to create a range 
of fake genomic locations I could use

```{r}
gr <- GenomicRanges::GRanges("chrX", IRanges::IRanges(1:6, width = 6:1))
gr
```

Now, and this is just a toy example, if I wanted to use some of these in a 
`data.frame`...


```{r}
d <- data.frame(a = 1:6, b = gr)
d
```

Hmmm... it looks like it unfolded and did something strange. It was expecting a
vector, not ... whatever `gr` is.

Not to worry, though - the Bioconductor ecosystem defines a `DataFrame` object 
that _does_ know how to deal with S4 classes just fine (there will be a lot of R
noise here, I can't help that - lots of masking)

```{r}
library(S4Vectors)
DataFrame(a = 1:6, b = gr)
```

You might say - "hey, that looks familiar! It's kind of like a `tibble`" and
you're right; the _types_ of each column are shown at the top, and in the case
of the `GRanges` object, it's a non-atomic type, handled correctly. There's
important differences compared to a `tibble`, though. Importantly, we can add 
row names to this just fine

```{r}
DataFrame(a = 1:6, b = gr, row.names = paste0("range", 1:6))
```

If we break the object, it will let us know because S4 performs object validation

```{r, error=TRUE}
a <- DataFrame(x = 1:3, y = LETTERS[1:3])
a
validObject(a)

# look away, I'm not supposed to do this
names(a@listData) <- NULL
a
validObject(a)
```

This is the right class for our sample metadata

```{r}
as(sample_metadata, "DataFrame")
```

Perfect!

If we look at an actual example of a `SummarizedExperiment`, e.g. from the {airway}
package which captures read counts per gene for an airway smooth muscle cell lines
[RNA-Seq](https://en.wikipedia.org/wiki/RNA-Seq) experiment

```{r}
library("airway")
data("airway")
se <- airway
se
```

we see a lot of information - the "dimensions" of this object is `r dim(se)[1]` 
genes measured for `r dim(se)[2]` samples. The 'rownames' element shows the IDs 
of these genes which will link the 'rowData' to the counts assay rows, and the 'colnames' 
element shows the sample IDs which will link the 'colData' to the counts assay columns.

Pulling this apart...

```{r}
cd <- colData(se)
cd
```

we see the sample metadata includes whether or not the sample was treated, and some 
details about the experiment. Similarly, the gene metadata details the various IDs 
and genomic locations.

```{r}
rowData(se)[1:3, ]
```

Tying these together is the actual assay data

```{r}
assay(se)[1:5, 1:5]
```

It all works really nicely - there are also additional places to store metadata
about the experiment shared across samples, and metadata about the columns themselves

```{r}
mcols(colData(se)) <- DataFrame(
  position = paste0("column ", 1:9), 
  is_ID = c(TRUE, TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE)
)
mcols(colData(se))
```

## Filtering a DataFrame

Now we get to a really interesting part - we want to do some analysis on this data. 

First, we want to look at the samples which were untreated. A `DataFrame` uses the 
same `[` subsetting mechanism as a `data.frame` so we could do

```{r}
cd[cd$dex == "untrt", c("SampleName", "avgLength")]
```

or even

```{r}
subset(cd, dex == "untrt", select = c("SampleName", "avgLength"))
```

and those work fine. 

What can often happen is you want the data for a specific sample. Sure, that ID 
might be encoded in a column, but typically the sample identifiers are used as 
the rownames of the `colData`, so we can get the data for sample "SRR1039512" with

```{r}
cd["SRR1039512", ]
```

What would be really nice, though, is to be able to use {dplyr}!

Let's try...

```{r, error=TRUE}
dplyr::filter(cd, dex == "untrt")
```

Nope, it's not defined for this class.

One of the most frequent workarounds for this is to convert this `DataFrame` to 
a `tibble`, at which point, yes, {dplyr} should work

```{r}
tbl_untrt <- dplyr::filter(tibble::as_tibble(cd), dex == "untrt")
tbl_untrt
```

That works, but there are two problems - both of them are that we now have a 
`tibble`, firstly because it now has no row names, and secondly, as a consequence, 
we can't "put it back" into the `SummarizedExperiment`.

We have the same problem with the gene information - we _can_ convert to `tibble` 
and use {dplyr}, but we're stuck there

```{r}
dplyr::filter(tibble::as_tibble(rowData(airway)), symbol == "CD38")
```

Critically, `tibble` suffers from the same lack of S4 support as regular `data.frame`s, 
so if there _are_ any of those columns, this workflow will break

```{r, error=TRUE}
d <- tibble::tibble(a = 1)
d
d$grX <- GenomicRanges::GRanges("chrX", IRanges::IRanges(1:6, width = 6:1))
```

What else can we do?

## Of Course I Have a Proposed Solution

Let's create a gnarly `DataFrame` with S4 columns and row names

```{r}
m <- mtcars[, c("cyl", "hp", "am", "gear", "disp")]
d <- as(m, "DataFrame")
d
d$grX <- GenomicRanges::GRanges("chrX", IRanges::IRanges(1:32, width=10))
d$grY <- GenomicRanges::GRanges("chrY", IRanges::IRanges(1:32, width = 10))
d$nl <- IRanges::NumericList(lapply(d$gear, function(n) round(rnorm(n), 2)))
d
```

and add some more metadata about the `colData` columns

```{r}
mcols(colData(se)) <- DataFrame(
  position = paste0("column ", 1:9), 
  is_ID = c(TRUE, TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE)
)
mcols(colData(se))
```

My solution was to write the {dplyr} verbs in a way that was compatible with `DataFrame` 
but which avoids passing through a `tibble` wherever possible. That became {DFplyr} 
and it's been sitting around [on GitHub](https://github.com/jonocarroll/DFplyr/) 
not doing much for the last 5 years.

I wrote a first version of this package despite being quite naive to the actual 
implementation of `DataFrame`, so I'm very grateful to Michael Lawrence and
Hervé Pagès who helped improve compatibility and pointed out bugs with what I'd
done.

Time to take it for a tour

```{r}
library(DFplyr)

colData(se)
cd <- colData(se) 
```

One thing I added was a custom 'label' if you're using this package within RStudio, 
in which case the Environment pane will show `cd` as "Formal class DataFrame (dplyr-compatible)".
That's not a change in the object itself, but rather all `DataFrame` objects will 
now show this, because {dplyr} verbs should work on them.

Now I can just `filter` the `colData` as if it was a `data.frame` or a `tibble`, 
but the result is still a `DataFrame`

```{r}
treated <- filter(cd, dex == "trt")
treated
```

Importantly, the row names and metadata are completely preserved, relevant to
this filtered subset

```{r}
rownames(treated)
mcols(treated)
```

```{r}
exp <- select(cd, Experiment, Sample, BioSample)
exp
mcols(exp)
```

I can _add_ more sample data if I have it

```{r}
cdq <- mutate(cd, quality = runif(nrow(cd)))
cdq
mcols(cdq)
```

and since no metadata about this new column was available, it has a blank row in 
the `mcols` entry.

If I perform an operation that doesn't make sense in terms of row names, they _will_ 
be removed

```{r}
cdq |> 
  group_by(dex) |> 
  summarise(avg_quality = mean(quality))
```

but rearranging them is fine

```{r}
cdq |> 
  arrange(desc(quality)) |> 
  slice(1:4)
```

One thing that `DataFrame` lacks - as does `data.frame` - is the concept of groups. 
{tibble} resolved this by adding a `"groups"` attribute, so I did the same in {DFplyr} -
I don't own {S4Vectors}, so I had to mask some functions in order to build in this 
support. I can now perform grouped operations on a `DataFrame` and have the 
grouping information printed like {tibble} does

```{r}
cd |> 
  group_by(dex) 

cd |> 
  group_by(dex) |> 
  summarise(meanAvgLength = mean(avgLength))
```

If I try to "put back" the subset `colData` I get an error, because there is 
assay data for samples we dropped

```{r, error=TRUE}
colData(se)
treated
colData(se) <- treated
```

But as long as I have some metadata for all the samples, it's fine - `cdq` was the 
version of `colData` with quality information, and you can see it's incorporated 
on the last line of this output

```{r}
colData(se) <- cdq
se
```

Storing S4 classes isn't all we can do - performing {dplyr} operations on S4 columns 
is perfectly fine; here, adding more S4 columns based on others

```{r}
myrange <- GenomicRanges::GRanges("chrX", IRanges::IRanges(2:5, width = 10))

d <- mutate(d, quality = runif(32), overlaps = GenomicRanges::countOverlaps(grX, myrange))
d <- mutate(d, nearest = plyranges::join_nearest(grX, myrange))
d
```

or filtering rows

```{r}
d |> 
  arrange(desc(quality)) |> 
  filter(overlaps > 0) |> 
  slice(1:4)
```

You don't necessarily need to extract the `DataFrame` into a variable, either - 
working with the extraction directly could be cleaner in some cases

```{r}
count(colData(se), cell)
```

<!-- ## Plotting -->

<!-- When I first wrote {DFplyr} a `DataFrame` wouldn't work in {ggplot2}, but it seems -->
<!-- it does now, so we can easily plot sample metadata -->

<!-- ```{r} -->
<!-- library(ggplot2) -->

<!-- ggplot(colData(airway), aes(dex, avgLength)) + -->
<!--   geom_boxplot() + -->
<!--   geom_point(aes(col = cell), position = position_jitter(width = 0.2), size = 4) -->
<!-- ``` -->

<!-- I suppose I can remove the support from {DFplyr} now. -->

## Other Ways to Filter

Using {dplyr} syntax on a `DataFrame` is very convenient, but that's only one 
component of a `SummarizedExperiment` - it would be great to be able to extend 
this further and do something like

```r
filter(airway, rows = ..., cols = ...)
```

It _is_ possible to do something like this - if I generate IDs of the 'rows' and 
'columns' I want to subset to, I can pass these in to a `[` extraction

```{r}
untrt <- colData(airway) |> filter(dex == "untrt") |> rownames()
untrt
genes <- rowData(airway)[c(1:3, 8:10), ] |> rownames()
genes

airway_sub <- airway[genes, untrt]
airway_sub
dim(airway_sub)
colData(airway_sub)
rowData(airway_sub)
```

Notice that this new object now has only 6 genes and 4 samples (the original has
`r dim(airway)[1]` genes and `r dim(airway)[2]` samples).

This sort of filtering is even nicer in `MultiAssayExperiment` where multiple 
`SummarizedExperiments` (or similar objects) are aggregated into a super object 
where the `colData` may be relevant to samples which appear in multiple assays.

![MultiAssayExperiment data layout](images/mae.png)

`MultiAssayExperiment` has some of the best written [vignettes](https://bioconductor.org/packages/release/bioc/vignettes/MultiAssayExperiment/inst/doc/QuickStartMultiAssay.html) 
I've seen, and I thoroughly recommend reading them if you have any need to use
this format

```{r}
library(MultiAssayExperiment)
```

(building the object not shown)

```{r, echo = FALSE}
example("ExperimentList", echo = FALSE)

exprmap <- data.frame(
  primary = c("Jack", "Jill", "Barbara", "Bob"),
  colname = c("array1", "array2", "array3", "array4"),
  stringsAsFactors = FALSE)

methylmap <- data.frame(
  primary = c("Jack", "Jack", "Jill", "Barbara", "Bob"),
  colname = c("methyl1", "methyl2", "methyl3", "methyl4", "methyl5"),
  stringsAsFactors = FALSE)

rnamap <- data.frame(
  primary = c("Jack", "Jill", "Bob", "Barbara"),
  colname = c("samparray1", "samparray2", "samparray3", "samparray4"),
  stringsAsFactors = FALSE)

gistmap <- data.frame(
  primary = c("Jack", "Bob", "Jill"),
  colname = c("samp0", "samp1", "samp2"),
  stringsAsFactors = FALSE)

## Combine as a named list and convert to a DataFrame
maplist <- list(Affy = exprmap, 
                Methyl450k = methylmap,
                RNASeqGene = rnamap, 
                GISTIC = gistmap
)

## Create a sampleMap
sampMap <- listToMap(maplist)
## Create an example phenotype data
colDat <- data.frame(sex = c("M", "F", "M", "F"), 
                     age = 38:41,
                     row.names = c("Jack", "Jill", "Bob", "Barbara"))
```

```{r}
mae <- MultiAssayExperiment(experiments = ExpList, 
                            colData = colDat,
                            sampleMap = sampMap
)

mae
colData(mae)
```

Subsetting the different dimensions (rows, columns, assays) can be done with the 
following format

```r
myMultiAssay[rows, columns, assays]
```

and since `mae$x` is defined to extract a `colData` column, I can subset this 
object to measurements of two genes in any assay for just the male subjects

```{r}
mae[c("ENST00000355076", "ENST00000383323"), mae$sex == "M", ]
```

All of that brings us to the [tidyOmics](https://tidyomics.com/) project which
aims to create tidy analysis packages for omics data. One of the packages there 
is `tidySummarizedExperiment` which is a reframing of `SummarizedExperiment` in 
a 'tidy' sense

```{r}
# remotes::install_github("stemangiola/tidySummarizedExperiment")
tidySummarizedExperiment::pasilla
```

If you're already familiar with `MultiAssayExperiment` then you may find this 
somewhat familiar to the `longFormat` output there

```{r}
longFormat(mae)
```

## Summary

That was a bit long winded, but I've been wanting to spell out my love for rownames 
which comes from this Bioconductor approach for some time. {DFplyr} is a bit of a 
mess internally, but I believe it has promise to be useful, so I'm interested in 
use-cases, failure modes, etc... The tidyOmics project defines a lot of new structures 
which need to interact with `DataFrame`s and I'm reasonably sure that {DFplyr} can 
help with that.

If you have comments, suggestions, or improvements - or if you think {DFplyr} could 
be useful to you, feel free to use the comment section below, or hit me up on
[Mastodon](https://fosstodon.org/@jonocarroll).

<br />
<details>
  <summary>
    <tt>devtools::session_info()</tt>
  </summary>
```{r sessionInfo, echo = FALSE}
devtools::session_info()
```
</details>
<br />
